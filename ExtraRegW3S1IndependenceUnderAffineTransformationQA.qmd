---
title: "Measurable sets"
subtitle: QA
format:
  html:
    embed-resources: true
---

# Measurable sets

## **1. Introduction to Measurable Sets**

### **1.1 The Sample Space and Events**

In probability theory, we study random experiments, each of which has a set of possible outcomes. The **sample space**, denoted by $\Omega$, is the set of all possible outcomes of an experiment.

An **event** is any subset of the sample space $\Omega$. For example, when flipping a coin, $\Omega = \{\text{Heads}, \text{Tails}\}$, and an event could be getting "Heads," which corresponds to the set $\{\text{Heads}\}$.

### **1.2 Sigma-Algebras ($\sigma$-Algebras)**

Not all subsets of $\Omega$ are events we can assign probabilities to, especially when dealing with infinite sample spaces. To handle this rigorously, we introduce the concept of a **sigma-algebra** ($\sigma$-algebra).

A **sigma-algebra** $\mathcal{F}$ over a set $\Omega$ is a collection of subsets of $\Omega$ satisfying three properties:

1. **Contains the Sample Space:**
   $$
   \Omega \in \mathcal{F}.
   $$
2. **Closed Under Complements:**
   $$
   \text{If } A \in \mathcal{F}, \text{ then } A^c = \Omega \setminus A \in \mathcal{F}.
   $$
3. **Closed Under Countable Unions:**
   $$
   \text{If } A_1, A_2, A_3, \dots \in \mathcal{F}, \text{ then } \bigcup_{i=1}^\infty A_i \in \mathcal{F}.
   $$

Subsets in $\mathcal{F}$ are called **measurable sets**.

### **1.3 Probability Measure**

A **probability measure** $P$ is a function $P: \mathcal{F} \rightarrow [0,1]$ that assigns a probability to each event (measurable set) in $\mathcal{F}$, satisfying:

1. **Non-negativity:**
   $$
   P(A) \geq 0 \text{ for all } A \in \mathcal{F}.
   $$
2. **Normalization:**
   $$
   P(\Omega) = 1.
   $$
3. **Countable Additivity:**
   $$
   \text{If } \{A_i\}_{i=1}^\infty \text{ are disjoint events in } \mathcal{F}, \text{ then } P\left( \bigcup_{i=1}^\infty A_i \right) = \sum_{i=1}^\infty P(A_i).
   $$

---

## **2. Measurable Functions and Random Variables**

### **2.1 Measurable Functions**

A function $X: \Omega \rightarrow \mathbb{R}$ is called a **measurable function** (or a **random variable**) if, for every Borel set $B \subseteq \mathbb{R}$, the pre-image $X^{-1}(B)$ is in $\mathcal{F}$:

$$
X^{-1}(B) = \{\omega \in \Omega : X(\omega) \in B\} \in \mathcal{F}.
$$

**Borel sets** are the sigma-algebra generated by all open intervals in $\mathbb{R}$. They include intervals, unions of intervals, and limits of sequences of intervals.

### **2.2 Random Vectors**

A **random vector** $\mathbf{X} = (X_1, X_2, \dots, X_n)$ is a vector where each component $X_i$ is a random variable.

- The random vector $\mathbf{X}$ is measurable if, for any Borel set $B \subseteq \mathbb{R}^n$, the pre-image $\mathbf{X}^{-1}(B)$ is in $\mathcal{F}$.

---

## **3. Independence in Probability Theory**

### **3.1 Independence of Events**

Two events $A$ and $B$ are **independent** if:

$$
P(A \cap B) = P(A) \cdot P(B).
$$

This means the occurrence of $A$ does not affect the probability of $B$ occurring, and vice versa.

### **3.2 Independence of Random Variables**

Random variables $X$ and $Y$ are **independent** if, for all Borel sets $A, B \subseteq \mathbb{R}$:

$$
P(X \in A \text{ and } Y \in B) = P(X \in A) \cdot P(Y \in B).
$$

This extends to random vectors $\mathbf{X}$ and $\mathbf{Y}$.

### **3.3 Sigma-Algebras Generated by Random Variables**

The **sigma-algebra generated** by a random variable $X$, denoted $\sigma(X)$, is the collection of all events that can be described in terms of $X$:

$$
\sigma(X) = \{ X^{-1}(B) : B \text{ is a Borel set in } \mathbb{R} \}.
$$

Random variables $X$ and $Y$ are independent if the sigma-algebras they generate are independent, meaning:

$$
P(A \cap B) = P(A) \cdot P(B), \quad \text{for all } A \in \sigma(X), B \in \sigma(Y).
$$

---

## **4. How Measurable Sets Relate to Independence**

When proving independence, measurable sets allow us to rigorously define and manipulate events involving random variables.

- **Events of the Form $\{ X \in A \}$:** These are measurable because $X$ is measurable and $A$ is a Borel set.
- **Intersection of Events:** The intersection $\{ X \in A \} \cap \{ Y \in B \}$ is measurable, allowing us to compute $P(X \in A \text{ and } Y \in B)$.

By working with measurable sets, we can apply the definitions and properties of probability measures to prove statements about independence.

---

## **5. Questions and Answers (Q&A)**

### **Q1: What is a measurable set in probability theory?**

**A1:** A measurable set is a subset of the sample space $\Omega$ that belongs to the sigma-algebra $\mathcal{F}$. These are the sets (events) to which we can assign probabilities using the probability measure $P$.

---

### **Q2: Why are sigma-algebras important in probability?**

**A2:** Sigma-algebras provide a structured way to define which events are measurable and ensure that operations like complementation and countable unions remain within the realm of measurable events. This is crucial for defining a consistent probability measure, especially when dealing with infinite or uncountable sample spaces.

---

### **Q3: How does measurability of a function (random variable) ensure that probabilities are well-defined?**

**A3:** A measurable function $X$ ensures that for any Borel set $B \subseteq \mathbb{R}$, the pre-image $X^{-1}(B)$ is a measurable set in $\Omega$. This allows us to define $P(X \in B)$ because $X^{-1}(B)$ is in $\mathcal{F}$, and the probability measure $P$ is defined on $\mathcal{F}$.

---

### **Q4: Can you explain independence in terms of measurable sets?**

**A4:** Yes. Random variables $X$ and $Y$ are independent if, for all Borel sets $A, B \subseteq \mathbb{R}$:

$$
P(\{ X \in A \} \cap \{ Y \in B \}) = P(X \in A) \cdot P(Y \in B).
$$

Here, $\{ X \in A \}$ and $\{ Y \in B \}$ are measurable sets in $\sigma(X)$ and $\sigma(Y)$, respectively. Their intersection is also measurable, allowing us to compute the probabilities and check for independence.

---

### **Q5: How do affine transformations relate to measurable sets and independence?**

**A5:** Affine transformations are functions of the form $\mathbf{U} = \mathbf{A} \mathbf{X} + \mathbf{b}$, where $\mathbf{A}$ is an invertible matrix and $\mathbf{b}$ is a vector. If $\mathbf{X}$ is a random vector, then $\mathbf{U}$ is also a random vector.

- **Measurability:** The affine transformation $\mathbf{U}$ is measurable because it is a continuous function of $\mathbf{X}$, and compositions of measurable functions are measurable.
- **Independence:** If $\mathbf{X}$ and $\mathbf{Y}$ are independent, their affine transformations $\mathbf{U}$ and $\mathbf{V}$ are also independent because measurable events involving $\mathbf{U}$ and $\mathbf{V}$ can be traced back to measurable events involving $\mathbf{X}$ and $\mathbf{Y}$.

---

### **Q6: In the proof of independence, why do we consider measurable sets like $S$ and $T$?**

**A6:** In the proof, we define sets $S$ and $T$ as pre-images of measurable sets under affine transformations:

$$
S = \{ \mathbf{x} \in \mathbb{R}^n : \mathbf{A} \mathbf{x} + \mathbf{b} \in A \}, \quad T = \{ \mathbf{y} \in \mathbb{R}^m : \mathbf{C} \mathbf{y} + \mathbf{d} \in B \}.
$$

These sets are measurable because affine transformations are measurable functions. By expressing probabilities involving $\mathbf{U}$ and $\mathbf{V}$ in terms of $\mathbf{X}$ and $\mathbf{Y}$, we can apply the definition of independence using measurable sets.

---

### **Q7: What is the significance of the pre-image in the context of measurable functions?**

**A7:** The pre-image $X^{-1}(B)$ tells us which outcomes in $\Omega$ lead to $X$ taking values in $B$. If $B$ is a Borel set and $X$ is measurable, then $X^{-1}(B)$ is a measurable set in $\Omega$, ensuring that $P(X \in B)$ is well-defined.

---

### **Q8: How do measurable sets help in defining joint distributions and independence?**

**A8:** The joint distribution of random variables $X$ and $Y$ is defined on events of the form $\{ X \in A, Y \in B \}$, which are measurable subsets of $\Omega$. Independence requires that the joint probability of these events equals the product of their marginal probabilities. Measurable sets ensure that these probabilities are well-defined and that properties like countable additivity can be applied.

---

### **Q9: Can you summarize the relationship between measurable sets, random variables, and independence?**

**A9:** Measurable sets are the building blocks of events in probability theory. Random variables are measurable functions mapping outcomes to real numbers, allowing us to define events like $\{ X \in A \}$ based on subsets $A$ of $\mathbb{R}$. Independence of random variables is defined through the probabilities of these measurable events, specifically requiring that the probability of their intersection equals the product of their probabilities. Thus, measurable sets are essential for defining and analyzing independence.

---

## **6. Conclusion**

Measurable sets provide a rigorous foundation for defining events, random variables, and probabilities in probability theory. Understanding measurable sets and sigma-algebras is crucial for grasping concepts like independence, especially when working with random variables and their transformations.

Certainly! The need for a rigorous definition of an "event" arises when dealing with complex or infinite sample spaces, where not all subsets can be assigned probabilities in a consistent and meaningful way. Without such rigor, we encounter paradoxes and contradictions that undermine the foundation of probability theory.

Let me provide an example that illustrates why we need a rigorous definition using measurable sets and sigma-algebras.

---

# Motivation for rigorous definitions of events

## **Example: The Vitali Set and Non-Measurable Sets**

### **Background**

Consider the sample space $\Omega = [0, 1]$, representing all real numbers between 0 and 1. Intuitively, we might think we can assign a probability to every subset of $\Omega$. However, this leads to contradictions when dealing with certain subsets, such as the **Vitali set**.

### **Constructing the Vitali Set**

1. **Equivalence Relation:**

   Define an equivalence relation $\sim$ on $[0, 1]$ by declaring two numbers equivalent if their difference is a rational number:

   $$
   x \sim y \quad \text{if and only if} \quad x - y \in \mathbb{Q}.
   $$

   This partitions $[0, 1]$ into equivalence classes where each class contains all numbers differing by a rational number.

2. **Selection of Representatives:**

   From each equivalence class, select exactly one representative. The set of these representatives is called a **Vitali set**, denoted by $V$.

   - **Note:** The Vitali set $V$ is uncountable but has specific properties that make it non-measurable.

### **Problem with Assigning Probability**

Suppose we try to define a probability measure $P$ on all subsets of $[0, 1]$ that is translation-invariant and countably additive.

- **Translation-Invariant:** For any set $A \subseteq [0, 1]$ and rational number $r \in [0, 1]$, the measure satisfies:

  $$
  P(A + r \mod 1) = P(A).
  $$

- **Countably Additive:** For any countable collection of disjoint sets $\{A_i\}$:

  $$
  P\left( \bigcup_{i} A_i \right) = \sum_{i} P(A_i).
  $$

However, assigning a measure to the Vitali set $V$ leads to contradictions.

### **Demonstration of the Contradiction**

1. **Create Translations of $V$:**

   For each rational number $r \in \mathbb{Q} \cap [0, 1]$, define:

   $$
   V_r = (V + r) \mod 1.
   $$

   Each $V_r$ is a translation of $V$ and should have the same measure if $V$ were measurable.

2. **Covering $[0,1]$ with Translated Sets:**

   The union of all these translated sets covers $[0, 1]$:

   $$
   [0, 1] = \bigcup_{r \in \mathbb{Q} \cap [0,1]} V_r.
   $$

   The sets $V_r$ are pairwise disjoint because each element in $[0, 1]$ belongs to exactly one equivalence class.

3. **Attempt to Assign Measure:**

   Let $m = P(V)$ be the measure of the Vitali set.

   - Since the $V_r$ are disjoint and cover $[0, 1]$:

     $$
     P([0, 1]) = \sum_{r \in \mathbb{Q} \cap [0,1]} P(V_r) = \sum_{r \in \mathbb{Q} \cap [0,1]} m.
     $$

   - The set of rational numbers in $[0, 1]$ is countable, so the sum becomes:

     $$
     P([0, 1]) = m \cdot \aleph_0,
     $$

     where $\aleph_0$ denotes the countable infinity.

4. **Contradiction:**

   - If $m = 0$:

     $$
     P([0, 1]) = 0 \cdot \aleph_0 = 0,
     $$

     which contradicts $P([0, 1]) = 1$.

   - If $m > 0$:

     $$
     P([0, 1]) = m \cdot \aleph_0 = \infty,
     $$

     again contradicting $P([0, 1]) = 1$.

   - There's no finite, non-zero value of $m$ that satisfies $P([0, 1]) = 1$.

### **Conclusion**

This contradiction shows that the Vitali set $V$ cannot be assigned a Lebesgue measure (probability) in a way that is consistent with the axioms of probability. Specifically, it violates countable additivity and the requirement that the total measure of $[0, 1]$ is 1.

---

## **Why We Need a Rigorous Definition of an "Event"**

### **1. Avoiding Non-Measurable Sets**

- **Non-Measurable Sets:** Sets like the Vitali set are non-measurable; they cannot be assigned a probability in a way that satisfies the axioms of probability theory.
- **Measurable Sets:** By restricting our attention to measurable sets (those in a sigma-algebra), we ensure that probabilities are well-defined and that operations like countable additivity hold.

### **2. Ensuring Consistency and Mathematical Rigor**

- **Sigma-Algebras ($\sigma$-Algebras):** A sigma-algebra is a collection of subsets (events) closed under complementation and countable unions and contains the sample space $\Omega$.
- **Probability Measure:** Defined on a sigma-algebra, a probability measure assigns probabilities to events in a way that is consistent and satisfies the axioms of probability.

### **3. Preserving the Axioms of Probability**

- **Countable Additivity:** Essential for the probability measure to behave predictably when dealing with infinite collections of events.
- **Total Measure:** Ensures that the measure of the entire sample space is 1.

### **4. Handling Infinite and Uncountable Sample Spaces**

- **Complexity of Infinite Sets:** In uncountable sample spaces like $[0, 1]$, not all subsets are "well-behaved" in terms of measure.
- **Need for Measurable Sets:** Restricting to measurable sets allows us to handle infinite sample spaces without encountering contradictions.

---

## **Additional Perspective:**

### **Lebesgue Measure and Borel Sets**

- **Borel Sets:** Generated from open intervals through countable unions, intersections, and complements.
- **Lebesgue Measure:** Extends the concept of length to a wider class of sets, including Borel sets, but still excludes non-measurable sets like the Vitali set.

### **Implications in Probability Theory**

- **Random Variables:** Measurable functions from a probability space to the real numbers.
- **Events Defined via Random Variables:** Events like $\{ X \in A \}$ are measurable if $A$ is a Borel set, ensuring that $P(X \in A)$ is well-defined.

---

## **Summary**

This example illustrates that without a rigorous definition of an "event" (as a measurable set within a sigma-algebra), we cannot consistently assign probabilities to all subsets of a sample space, especially when dealing with infinite or uncountable sets. The rigorous approach ensures:

- **Consistency:** All assigned probabilities are consistent with the axioms of probability.
- **Avoidance of Paradoxes:** Excludes non-measurable sets that lead to contradictions.
- **Mathematical Foundation:** Provides a solid foundation for advanced probability theory and applications.

---

## **Key Takeaways**

- **Rigorous Definitions Are Essential:** They prevent contradictions and ensure that probability theory is mathematically sound.
- **Not All Sets Are Measurable:** Some subsets of infinite sample spaces cannot be assigned probabilities in a consistent way.
- **Sigma-Algebras Restrict to Measurable Events:** This allows us to define probability measures that are well-behaved and adhere to the axioms.

---

## **Further Questions?**

Please let me know if you'd like more clarification on any part of this example or have additional questions about measurable sets and their role in probability theory!

## Equivalence classes

Certainly! Understanding equivalence relations and equivalence classes is fundamental in many areas of mathematics, including probability theory, set theory, and algebra. I'll explain these concepts step by step and provide examples to illustrate them.

---

## **1. Equivalence Relations**

### **1.1 Definition**

An **equivalence relation** is a way to formalize the idea of elements being "equivalent" in some sense within a set. Formally, a binary relation $\sim$ on a set $S$ is called an equivalence relation if it satisfies three properties:

1. **Reflexivity:**
   - Every element is related to itself.
   - For all $a \in S$,
     $$
     a \sim a.
     $$
2. **Symmetry:**
   - If an element $a$ is related to $b$, then $b$ is related to $a$.
   - For all $a, b \in S$,
     $$
     \text{If } a \sim b, \text{ then } b \sim a.
     $$
3. **Transitivity:**
   - If $a$ is related to $b$ and $b$ is related to $c$, then $a$ is related to $c$.
   - For all $a, b, c \in S$,
     $$
     \text{If } a \sim b \text{ and } b \sim c, \text{ then } a \sim c.
     $$

These properties ensure that the relation $\sim$ groups elements in a meaningful and consistent way.

### **1.2 Examples of Equivalence Relations**

#### **Example 1: Congruence Modulo $n$**

- **Set:** The set of integers $\mathbb{Z}$.
- **Relation:** For a fixed positive integer $n$, define $a \sim b$ if $n$ divides $a-b$.
- **Properties:**
  - **Reflexive:** $a - a = 0$ is divisible by $n$, so $a \sim a$.
  - **Symmetric:** If $a \sim b$, then $a - b$ is divisible by $n$, so $b - a$ is also divisible by $n$, hence $b \sim a$.
  - **Transitive:** If $a \sim b$ and $b \sim c$, then $a - c = (a - b) + (b - c)$ is divisible by $n$, so $a \sim c$.

#### **Example 2: Similar Triangles**

- **Set:** The set of all triangles in Euclidean geometry.
- **Relation:** Two triangles are related if they are similar (same shape but possibly different sizes).
- **Properties:**
  - **Reflexive:** Any triangle is similar to itself.
  - **Symmetric:** If triangle $A$ is similar to triangle $B$, then $B$ is similar to $A$.
  - **Transitive:** If triangle $A$ is similar to $B$, and $B$ is similar to $C$, then $A$ is similar to $C$.

---

## **2. Equivalence Classes**

### **2.1 Definition**

Given an equivalence relation $\sim$ on a set $S$, the **equivalence class** of an element $a \in S$ is the set of all elements in $S$ that are equivalent to $a$:

$$
[a] = \{ x \in S : x \sim a \}.
$$

### **2.2 Properties of Equivalence Classes**

- **Partitioning of $S$:** The set of all equivalence classes forms a partition of $S$, meaning:
  - **Every element belongs to exactly one equivalence class.**
  - **The union of all equivalence classes is $S$.**
- **Disjointness:** If $a \not\sim b$, then $[a] \cap [b] = \emptyset$.
- **Covering $S$:** The collection of all equivalence classes covers the entire set $S$:
  $$
  S = \bigcup_{a \in S} [a].
  $$

### **2.3 Examples of Equivalence Classes**

#### **Example 1: Congruence Classes Modulo $n$**

- **Set:** $\mathbb{Z}$.
- **Equivalence Classes:** For $n = 3$, the equivalence classes are:
  - $[0] = \{ \dots, -6, -3, 0, 3, 6, \dots \}$
  - $[1] = \{ \dots, -5, -2, 1, 4, 7, \dots \}$
  - $[2] = \{ \dots, -4, -1, 2, 5, 8, \dots \}$
- **Interpretation:** Each class contains all integers with the same remainder when divided by 3.

#### **Example 2: Partitioning People by Birth Year**

- **Set:** The set of all people.
- **Relation:** Two people are related if they were born in the same year.
- **Equivalence Classes:** Each equivalence class consists of all people born in a particular year.
- **Properties:** This relation partitions the set of all people into groups based on birth year.

---

## **3. Connection to the Vitali Set Example**

In the previous discussion about the Vitali set, we used an equivalence relation to construct a set that is non-measurable.

### **3.1 The Equivalence Relation**

- **Set:** $[0, 1]$, the interval of real numbers from 0 to 1.
- **Relation:** Define $x \sim y$ if $x - y$ is a rational number:
  $$
  x \sim y \quad \text{if and only if} \quad x - y \in \mathbb{Q}.
  $$
  
**Properties:**

1. **Reflexive:**
   - For any $x \in [0, 1]$, $x - x = 0 \in \mathbb{Q}$, so $x \sim x$.
2. **Symmetric:**
   - If $x \sim y$, then $x - y \in \mathbb{Q}$, so $y - x = -(x - y) \in \mathbb{Q}$, hence $y \sim x$.
3. **Transitive:**
   - If $x \sim y$ and $y \sim z$, then $x - y \in \mathbb{Q}$ and $y - z \in \mathbb{Q}$.
   - Adding these equations:
     $$
     (x - y) + (y - z) = x - z \in \mathbb{Q},
     $$
     so $x \sim z$.

### **3.2 Equivalence Classes in This Context**

- **Each Equivalence Class $[x]$:**
  - Contains all real numbers in $[0, 1]$ that differ from $x$ by a rational number.
  - Since the rationals are dense in the reals, each equivalence class is dense in $[0, 1]$.

- **Uncountably Many Equivalence Classes:**
  - There are uncountably many such classes because the reals are uncountable, and each class corresponds to an irrational "offset" from a representative.

### **3.3 Constructing the Vitali Set**

- **Selection of Representatives:**
  - Choose exactly one element from each equivalence class to form the Vitali set $V$.
  - **Note:** The Axiom of Choice is required to make such a selection because there is no explicit rule to choose representatives from uncountably many classes.

- **Properties of $V$:**
  - **Non-Measurable:** As shown earlier, $V$ cannot be assigned a Lebesgue measure without leading to contradictions.
  - **Dense Subset:** Since each equivalence class is dense in $[0, 1]$, $V$ is also dense in $[0, 1]$.

---

## **4. Importance of Equivalence Relations and Classes**

### **4.1 Partitioning Sets**

- **Organizing Elements:**
  - Equivalence relations allow us to group elements that share a common property.
- **Simplifying Problems:**
  - By working with equivalence classes, we can reduce complex problems to studying representative elements.

### **4.2 Applications in Mathematics**

- **Modular Arithmetic:**
  - Equivalence classes modulo $n$ are foundational in number theory and cryptography.
- **Topology and Geometry:**
  - Equivalence relations help define quotient spaces.
- **Probability Theory:**
  - As seen with the Vitali set, equivalence relations can lead to constructions that challenge our understanding of measure and integration.

---

## **5. Additional Examples**

### **Example 3: Identifying Angles**

- **Set:** Real numbers representing angles, with the understanding that angles differing by full rotations are equivalent.
- **Relation:** $a \sim b$ if $a - b$ is a multiple of $360^\circ$.
- **Equivalence Classes:** Each class corresponds to a unique angle between $0^\circ$ and $360^\circ$, representing all coterminal angles.

### **Example 4: Students Grouped by Major**

- **Set:** A set of students at a university.
- **Relation:** Two students are related if they have the same major.
- **Equivalence Classes:** Each class consists of all students in a particular major.
- **Purpose:** Useful for administrative purposes, statistical analyses, and organizing events.

---

## **6. Summary**

- **Equivalence Relation:** A binary relation that is reflexive, symmetric, and transitive.
- **Equivalence Class:** A subset of a set $S$ consisting of all elements equivalent to a particular element $a \in S$ under the equivalence relation.
- **Partitioning:** Equivalence relations partition the set $S$ into disjoint equivalence classes, covering the entire set without overlap.
- **Applications:** Equivalence relations and classes are used across various fields to group elements sharing common characteristics, simplify problems, and explore complex mathematical concepts.

---

## **7. Conclusion**

Understanding equivalence relations and equivalence classes provides a powerful tool for organizing and analyzing sets based on shared properties. They are foundational concepts that appear in many areas of mathematics and are essential for rigorous mathematical reasoning.

---

## Q&A on the above

---

**Proof of Independence for Multivariate Variables and Their Affine Transformations**

*Question:* What are the random vectors involved?

*Answer:* Random vectors $\mathbf{X} \in \mathbb{R}^n$ and $\mathbf{Y} \in \mathbb{R}^m$.

*Question:* What are affine transformations of these vectors?

*Answer:* Transformations of the form $\mathbf{U} = \mathbf{A}\mathbf{X} + \mathbf{b}$ and $\mathbf{V} = \mathbf{C}\mathbf{Y} + \mathbf{d}$, where $\mathbf{A}$ and $\mathbf{C}$ are invertible matrices, and $\mathbf{b}$ and $\mathbf{d}$ are vectors.

*Question:* What theorem are we proving?

*Answer:* That $\mathbf{X}$ and $\mathbf{Y}$ are independent if and only if their affine transformations $\mathbf{U}$ and $\mathbf{V}$ are independent.

*Question:* What is the first direction of the proof?

*Answer:* Showing that if $\mathbf{X}$ and $\mathbf{Y}$ are independent, then $\mathbf{U}$ and $\mathbf{V}$ are independent.

*Question:* How do we start this part of the proof?

*Answer:* By assuming $\mathbf{X}$ and $\mathbf{Y}$ are independent, so their joint density factors: $f_{\mathbf{X}, \mathbf{Y}}(\mathbf{x}, \mathbf{y}) = f_{\mathbf{X}}(\mathbf{x}) f_{\mathbf{Y}}(\mathbf{y})$.

*Question:* What transformations do we consider?

*Answer:* The affine transformations $\mathbf{U} = \mathbf{A}\mathbf{X} + \mathbf{b}$ and $\mathbf{V} = \mathbf{C}\mathbf{Y} + \mathbf{d}$.

*Question:* What are the inverse transformations?

*Answer:* $\mathbf{X} = \mathbf{A}^{-1}(\mathbf{U} - \mathbf{b})$ and $\mathbf{Y} = \mathbf{C}^{-1}(\mathbf{V} - \mathbf{d})$.

*Question:* How do we find the joint density of $\mathbf{U}$ and $\mathbf{V}$?

*Answer:* By performing a change of variables using the Jacobian determinant.

*Question:* What is the joint density function of $\mathbf{U}$ and $\mathbf{V}$?

*Answer:* $f_{\mathbf{U}, \mathbf{V}}(\mathbf{u}, \mathbf{v}) = f_{\mathbf{X}, \mathbf{Y}}(\mathbf{A}^{-1}(\mathbf{u} - \mathbf{b}), \mathbf{C}^{-1}(\mathbf{v} - \mathbf{d})) \left| \det(\mathbf{A}^{-1}) \det(\mathbf{C}^{-1}) \right|$.

*Question:* How does independence of $\mathbf{X}$ and $\mathbf{Y}$ help here?

*Answer:* Because $f_{\mathbf{X}, \mathbf{Y}}(\mathbf{x}, \mathbf{y}) = f_{\mathbf{X}}(\mathbf{x}) f_{\mathbf{Y}}(\mathbf{y})$, allowing us to factor the joint density.

*Question:* What conclusion do we reach?

*Answer:* That $f_{\mathbf{U}, \mathbf{V}}(\mathbf{u}, \mathbf{v}) = f_{\mathbf{U}}(\mathbf{u}) f_{\mathbf{V}}(\mathbf{v})$, so $\mathbf{U}$ and $\mathbf{V}$ are independent.

*Question:* What is the second direction of the proof?

*Answer:* Showing that if $\mathbf{U}$ and $\mathbf{V}$ are independent, then $\mathbf{X}$ and $\mathbf{Y}$ are independent.

*Question:* How do we begin this part?

*Answer:* By assuming $\mathbf{U}$ and $\mathbf{V}$ are independent, so $f_{\mathbf{U}, \mathbf{V}}(\mathbf{u}, \mathbf{v}) = f_{\mathbf{U}}(\mathbf{u}) f_{\mathbf{V}}(\mathbf{v})$.

*Question:* How do we find the joint density of $\mathbf{X}$ and $\mathbf{Y}$?

*Answer:* By changing variables back to $\mathbf{X}$ and $\mathbf{Y}$ using the inverse transformations.

*Question:* What is the joint density function of $\mathbf{X}$ and $\mathbf{Y}$?

*Answer:* $f_{\mathbf{X}, \mathbf{Y}}(\mathbf{x}, \mathbf{y}) = f_{\mathbf{U}, \mathbf{V}}(\mathbf{A}\mathbf{x} + \mathbf{b}, \mathbf{C}\mathbf{y} + \mathbf{d}) \left| \det(\mathbf{A}) \det(\mathbf{C}) \right|$.

*Question:* How does independence of $\mathbf{U}$ and $\mathbf{V}$ affect this?

*Answer:* Since $f_{\mathbf{U}, \mathbf{V}}(\mathbf{u}, \mathbf{v})$ factors, so does $f_{\mathbf{X}, \mathbf{Y}}(\mathbf{x}, \mathbf{y})$.

*Question:* What is the final conclusion?

*Answer:* That $f_{\mathbf{X}, \mathbf{Y}}(\mathbf{x}, \mathbf{y}) = f_{\mathbf{X}}(\mathbf{x}) f_{\mathbf{Y}}(\mathbf{y})$, so $\mathbf{X}$ and $\mathbf{Y}$ are independent.

---

**Measurable Sets and Their Relation to Independence**

*Question:* What is the sample space in probability?

*Answer:* The set of all possible outcomes, denoted $\Omega$.

*Question:* What is an event in this context?

*Answer:* A subset of the sample space $\Omega$.

*Question:* What is a sigma-algebra?

*Answer:* A collection $\mathcal{F}$ of subsets of $\Omega$ that includes $\Omega$, is closed under complementation, and closed under countable unions.

*Question:* What are measurable sets?

*Answer:* The subsets of $\Omega$ that belong to the sigma-algebra $\mathcal{F}$.

*Question:* Why are sigma-algebras important?

*Answer:* They define the events to which we can assign probabilities consistently.

*Question:* What is a probability measure?

*Answer:* A function $P$ assigning probabilities to events in $\mathcal{F}$, satisfying certain axioms like non-negativity, normalization, and countable additivity.

*Question:* What is a measurable function or random variable?

*Answer:* A function $X: \Omega \rightarrow \mathbb{R}$ such that for every Borel set $B$, the pre-image $X^{-1}(B)$ is in $\mathcal{F}$.

*Question:* How does measurability relate to random vectors?

*Answer:* Each component of a random vector must be a measurable function.

*Question:* How are events involving random variables defined?

*Answer:* As measurable sets like $\{ \omega \in \Omega : X(\omega) \in A \}$ where $A$ is a Borel set.

*Question:* How is independence defined using measurable sets?

*Answer:* Random variables $X$ and $Y$ are independent if $P(X \in A, Y \in B) = P(X \in A) P(Y \in B)$ for all Borel sets $A$ and $B$.

*Question:* Why are measurable sets essential for defining independence?

*Answer:* They ensure that the probabilities of events involving random variables are well-defined and consistent.

---

**Example Illustrating the Need for Rigorous Definition of an "Event"**

*Question:* What is the sample space in the Vitali set example?

*Answer:* The interval $[0, 1]$.

*Question:* What equivalence relation is defined on $[0, 1]$?

*Answer:* Two numbers $x$ and $y$ are equivalent if $x - y$ is rational.

*Question:* What is an equivalence class here?

*Answer:* A set of numbers in $[0, 1]$ that differ from each other by rational numbers.

*Question:* What is the Vitali set?

*Answer:* A set containing exactly one representative from each equivalence class.

*Question:* Why can't we assign a Lebesgue measure to the Vitali set?

*Answer:* Because it leads to contradictions with the axioms of probability, specifically with countable additivity and total measure.

*Question:* What contradiction arises when assigning measure to the Vitali set?

*Answer:* The measure of $[0, 1]$ becomes zero or infinite, conflicting with $P([0, 1]) = 1$.

*Question:* What does this example demonstrate?

*Answer:* That some subsets are non-measurable and cannot be assigned probabilities, highlighting the need for measurable sets.

*Question:* Why is a rigorous definition of an "event" necessary?

*Answer:* To avoid paradoxes and ensure probabilities are consistently defined.

---

**Equivalence Relations and Equivalence Classes**

*Question:* What is an equivalence relation?

*Answer:* A relation that is reflexive, symmetric, and transitive.

*Question:* What does reflexive mean?

*Answer:* Every element is related to itself ($a \sim a$).

*Question:* What does symmetric mean?

*Answer:* If $a \sim b$, then $b \sim a$.

*Question:* What does transitive mean?

*Answer:* If $a \sim b$ and $b \sim c$, then $a \sim c$.

*Question:* What is an equivalence class?

*Answer:* A set of elements all equivalent to each other under the equivalence relation.

*Question:* How do equivalence classes partition a set?

*Answer:* They divide the set into disjoint subsets covering the entire set.

*Question:* Can you give an example of an equivalence relation?

*Answer:* Congruence modulo $n$ on integers.

*Question:* What does congruence modulo $n$ mean?

*Answer:* Integers $a$ and $b$ are equivalent if $a - b$ is divisible by $n$.

*Question:* How are equivalence classes used in the Vitali set?

*Answer:* By selecting one element from each class where $x \sim y$ if $x - y$ is rational.

*Question:* What is the role of equivalence relations in mathematics?

*Answer:* They help classify and group elements with common properties.

---

**Conclusion**

*Question:* Why is understanding these concepts important?

*Answer:* Because they provide the foundational framework for probability theory and mathematical rigor in defining events and independence.

